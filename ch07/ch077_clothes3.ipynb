{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>black</th>\n",
       "      <th>blue</th>\n",
       "      <th>brown</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>white</th>\n",
       "      <th>dress</th>\n",
       "      <th>shirt</th>\n",
       "      <th>pants</th>\n",
       "      <th>shorts</th>\n",
       "      <th>shoes</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./clothes_dataset\\green_shoes\\f1f33bed259f4b38...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./clothes_dataset\\brown_pants\\8a797ffb710eefe3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./clothes_dataset\\white_dress\\ef86bf5eee72dbe8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./clothes_dataset\\black_shoes\\ff7f558959757ab7...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./clothes_dataset\\blue_pants\\b354ab5371b90d5eb...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  black  blue  brown  \\\n",
       "0  ./clothes_dataset\\green_shoes\\f1f33bed259f4b38...      0     0      0   \n",
       "1  ./clothes_dataset\\brown_pants\\8a797ffb710eefe3...      0     0      1   \n",
       "2  ./clothes_dataset\\white_dress\\ef86bf5eee72dbe8...      0     0      0   \n",
       "3  ./clothes_dataset\\black_shoes\\ff7f558959757ab7...      1     0      0   \n",
       "4  ./clothes_dataset\\blue_pants\\b354ab5371b90d5eb...      0     1      0   \n",
       "\n",
       "   green  red  white  dress  shirt  pants  shorts  shoes  color  \n",
       "0      1    0      0      0      0      0       0      1      3  \n",
       "1      0    0      0      0      0      1       0      0      2  \n",
       "2      0    0      1      1      0      0       0      0      5  \n",
       "3      0    0      0      0      0      0       0      1      0  \n",
       "4      0    0      0      0      0      1       0      0      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Concatenate\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "DATA_PATH = 'C:/Work/1stDL/Roadbook_DeepLearning-master/TF_2.12v/code/clothes_classification/csv_data/colorinfo'\n",
    "\n",
    "train_df = pd.read_csv(DATA_PATH + '/train_color.csv')\n",
    "val_df = pd.read_csv(DATA_PATH + '/val_color.csv')\n",
    "test_df = pd.read_csv(DATA_PATH + '/test_color.csv')\n",
    "\n",
    "# Colab에서 사용한다면, 다음 코드 주석을 풀고, 실행시킵니다.\n",
    "# train_df['image'] = train_df['image'].apply(lambda x: str(x).replace('//', '/'))\n",
    "# val_df['image'] = val_df['image'].apply(lambda x: str(x).replace('//', '/'))\n",
    "# test_df['image'] = test_df['image'].apply(lambda x: str(x).replace('//', '/'))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제네레이터 정의하기\n",
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size\n",
    "    \n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size = 32, target_size = (112, 112),\n",
    "                shuffle = True, \n",
    "                training = True):\n",
    "        self.len_df = len(df)\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.training = training\n",
    "\n",
    "        if training:\n",
    "            self.class_col = ['black', 'blue', 'brown', 'green', 'red', 'white',\n",
    "                              'dress', 'shirt', 'pants', 'shorts', 'shoes']\n",
    "        else:\n",
    "            self.class_col = None\n",
    "\n",
    "        # 제네레이터를 통해 이미지를 불러옵니다.\n",
    "        self.generator = ImageDataGenerator(rescale=1./255)\n",
    "        self.df_generator = self.generator.flow_from_dataframe(dataframe = df,\n",
    "                                                               directory = 'C:/Work/1stDL/Roadbook_DeepLearning-master/TF_2.12v/code/clothes_classification',\n",
    "                                                               x_col = 'image',\n",
    "                                                               y_col = self.class_col if training else None,\n",
    "                                                               target_size = self.target_size,\n",
    "                                                               color_mode = 'rgb',\n",
    "                                                               class_mode = 'raw' if training else None,\n",
    "                                                               batch_size = self.batch_size,\n",
    "                                                               shuffle = True,\n",
    "                                                               seed = 42)\n",
    "        self.colors_df = df['color']\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.len_df) / self.batch_size)\n",
    "    \n",
    "    # 데이터를 섞습니다.\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.len_df)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    # ([이미지 데이터, 색 정보], 레이블)을 반환합니다.\n",
    "    # 이미지는 미리 정의한 제네레이터를 통해,\n",
    "    # 색 정보는 __data_generation 메소드를 활용합니다.\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = (index + 1) * self.batch_size if (index + 1) * self.batch_size < self.len_df else (self.len_df + 1)\n",
    "    \n",
    "        indexes = self.indexes[start:end]\n",
    "        colors = self.__data_generation(indexes)\n",
    "\n",
    "        if self.training:\n",
    "                images, labels = self.df_generator.__getitem__(index)\n",
    "                return {\"images\": images, \"colors\": colors}, labels\n",
    "        else:\n",
    "            images = self.df_generator.__getitem__(index)\n",
    "            return {\"images\": images, \"colors\": colors}\n",
    "        \n",
    "    def __data_generation(self, indexes):\n",
    "        colors = np.array([self.colors_df[k] for k in indexes])\n",
    "\n",
    "        return colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5578 validated image filenames.\n",
      "Found 2391 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = DataGenerator(train_df, \n",
    "                              batch_size = 32,\n",
    "                              target_size = (112, 112),\n",
    "                              shuffle = True,\n",
    "                              training = True)\n",
    "val_datagen = DataGenerator(val_df,\n",
    "                            batch_size = 32,\n",
    "                            target_size = (112, 112),\n",
    "                            shuffle = True,\n",
    "                            training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready!\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성하기\n",
    "\n",
    "def get_model():\n",
    "    img_input = Input(shape=(112, 112, 3), name='images')\n",
    "    color_input = Input(shape=[1], name='colors')\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(img_input)\n",
    "    x = MaxPooling2D((3, 3), strides = 2)(x)\n",
    "    x = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides = 2)(x)\n",
    "    x = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides = 2)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # 색 데이터를 병합합니다.\n",
    "    color_concat = Concatenate()([x, color_input])\n",
    "\n",
    "    x = Dense(64, activation = 'relu')(color_concat)\n",
    "    x = Dense(11, activation = 'sigmoid')(x)\n",
    "\n",
    "    # 다중 입력이기 때문에,\n",
    "    # inputs 인자에 리스트 형태로 입력 데이터를 전달합니다.\n",
    "    model = Model(inputs={'images': img_input, 'colors': color_input}, outputs=x)\n",
    "\n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['binary_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "print('model ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 344ms/step - binary_accuracy: 0.7833 - loss: 0.4782 - val_binary_accuracy: 0.8637 - val_loss: 0.3119\n",
      "Epoch 2/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 242ms/step - binary_accuracy: 0.8723 - loss: 0.3028 - val_binary_accuracy: 0.8906 - val_loss: 0.2619\n",
      "Epoch 3/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 242ms/step - binary_accuracy: 0.8946 - loss: 0.2557 - val_binary_accuracy: 0.9023 - val_loss: 0.2378\n",
      "Epoch 4/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 239ms/step - binary_accuracy: 0.9046 - loss: 0.2351 - val_binary_accuracy: 0.9067 - val_loss: 0.2251\n",
      "Epoch 5/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 240ms/step - binary_accuracy: 0.9106 - loss: 0.2196 - val_binary_accuracy: 0.9152 - val_loss: 0.2129\n",
      "Epoch 6/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 239ms/step - binary_accuracy: 0.9190 - loss: 0.2033 - val_binary_accuracy: 0.9166 - val_loss: 0.2098\n",
      "Epoch 7/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 239ms/step - binary_accuracy: 0.9221 - loss: 0.1994 - val_binary_accuracy: 0.9283 - val_loss: 0.1822\n",
      "Epoch 8/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 240ms/step - binary_accuracy: 0.9274 - loss: 0.1877 - val_binary_accuracy: 0.9324 - val_loss: 0.1788\n",
      "Epoch 9/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 239ms/step - binary_accuracy: 0.9348 - loss: 0.1697 - val_binary_accuracy: 0.9341 - val_loss: 0.1725\n",
      "Epoch 10/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 242ms/step - binary_accuracy: 0.9380 - loss: 0.1603 - val_binary_accuracy: 0.9379 - val_loss: 0.1663\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_datagen,\n",
    "                    validation_data = val_datagen,\n",
    "                    epochs = 10,\n",
    "                    batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_study",
   "language": "python",
   "name": "keras_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
